version: "3"

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    hostname: namenode
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    #network_mode: host
    networks:
      - bigdata
      
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    hostname: datanode
    restart: always
    ports:
      - "9864:9864"
      - "9866:9866"
      - "9867:9867"
      - "50010:50010"
      - "50020:50020"
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    #network_mode: host
    networks:
      - bigdata
      
  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    hostname: resourcemanager
    restart: always
    ports:
      - "8088:8088"
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode:9864"
    env_file:
      - ./hadoop.env
    #network_mode: host
    networks:
      - bigdata
      
  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    hostname: nodemanager
    restart: always
    ports:
      - "8042:8042"
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 resourcemanager:8088"
    env_file:
      - ./hadoop.env
    #network_mode: host
    networks:
      - bigdata
      
  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    hostname: historyserver
    restart: always
    ports:
      - "8188:8188"
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
    #network_mode: host      
    networks:
      - bigdata

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    hostname: hive-server
    #network_mode: host
    networks:
      - bigdata    
    env_file:
      - ./hadoop-hive.env
      - ./hadoop.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 resourcemanager:8088 hive-metastore:9083"
    ports:
      - "10000:10000"
      - "10002:10002"

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    hostname: hive-metastore
    #network_mode: host
    networks:
      - bigdata
    env_file:
      - ./hadoop-hive.env
      - ./hadoop.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 resourcemanager:8088 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"

  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    container_name: hive-metastore-postgresql
    hostname: hive-metastore-postgresql
    #network_mode: host
    networks:
      - bigdata
    ports:
      - "5432:5432"

    #nanp-mysql:
  #  image: mysql:8.0
  #  container_name: nanp-mysql
  #  hostname: nanp-mysql
  #  environment:
  #    - MYSQL_ROOT_PASSWORD=mysql
  #    - MYSQL_USER=nanp
  #    - MYSQL_PASSWORD=nanp
  #  volumes:
  #    - mysql_data:/var/lib/mysql
  #    - share_data:/partage
  #  #network_mode: host
  #  networks:
  #    - bigdata
  #  ports:
  #    - "8889:3306"
  #    
  #nanp-nifi:
  #  image: apache/nifi:1.24.0
  #  container_name: nanp-nifi
  #  hostname: nanp-nifi
  #  restart: always
  #  environment:
  #    - NIFI_WEB_HTTPS_PORT=8443
  #    - SINGLE_USER_CREDENTIALS_USERNAME=nifi_user
  #    - SINGLE_USER_CREDENTIALS_PASSWORD=2jeanrf9iPJCwWoWmNC8h1p9Xujd1RWb
  #  volumes:
  #    #- nifi_data:/opt/nifi/nifi-current/
  #    - share_data:/partage
  #  #network_mode: host
  #  networks:
  #    - bigdata
  #  ports:
  #    - "8887:8080"
  #    - "8443:8443"
   
  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
      - HADOOP_CONF_DIR=/partage/xml_spark
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
      - SPARK_MASTER=yarn
    volumes:
      - share_data:/partage
    networks:
      - bigdata
  spark-worker:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker
    hostname: spark-worker
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - HADOOP_CONF_DIR=/partage/xml_spark
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1G
      - SPARK_DRIVER_MEMORY=1G
      - SPARK_EXECUTOR_MEMORY=1G
    volumes:
      - share_data:/partage
    networks:
      - bigdata
    
volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:
  mysql_data:
    driver: local # Define the driver and options under the volume name
    driver_opts:
      type: none
      device: C:\Users\ngoun\Downloads\music\docker_volume\volume_mysql
      o: bind
  share_data:
    driver: local # Define the driver and options under the volume name
    driver_opts:
      type: none
      device: C:\Users\ngoun\Downloads\music\docker_volume\partage_nifi\partage
      o: bind
  
networks:
  bigdata:
#    name: bigdata
#    external: true
